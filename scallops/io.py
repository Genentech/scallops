"""This module provides a functionality for reading, processing, and saving imaging and experimental
data, with a focus on bio-imaging formats like TIFF, ND2, Zarr, and others.

It supports handling of metadata, conversion between data types, and integrates with external
libraries such as bioio, pandas, numpy for advanced image and data manipulation. The module is
designed to work efficiently with large datasets, offering support for lazy loading with Dask, and
facilitating the organization and extraction of meaningful insights from complex experimental data
structures.
"""

from __future__ import annotations

import atexit
import logging
import math
import os
import re
import struct
import tempfile
import warnings
import weakref
from collections import defaultdict
from collections.abc import Callable, KeysView
from io import BytesIO
from itertools import product
from pathlib import Path
from string import Formatter
from typing import Any, Dict, Generator, Literal, Mapping, Sequence

import anndata
import bioio
import bioio_ome_zarr
import bioio_tifffile
import dask
import dask.array as da
import dask.dataframe as dd
import fsspec
import numpy as np
import ome_types
import pandas as pd
import pyarrow.parquet as pq
import xarray as xr
import zarr
from anndata._io.specs import read_elem
from anndata.experimental import read_dispatched
from bioio.writers import OmeTiffWriter
from dask.bag import from_sequence
from dask.delayed import Delayed, delayed
from dask.diagnostics import ProgressBar
from natsort import natsorted
from ome_types import OME
from ome_types._autogenerated.ome_2016_06 import MapAnnotation
from scipy.ndimage import gaussian_filter
from tifffile import tifffile
from xarray.core.utils import equivalent
from zarr.storage import StoreLike

from scallops.experiment.elements import Experiment, _LazyLoadData
from scallops.externals.tifffile2014 import imsave
from scallops.utils import forceTCZYX, mlcs
from scallops.xr import _crop
from scallops.zarr_io import _get_store_path, _read_zarr_experiment, read_ome_zarr_array

logger = logging.getLogger("scallops")


def _add_suffix(path: str, suffix: str) -> str:
    """Adds a suffix to a given file path before the file extension.

    :param path: str
        The original file path.
    :param suffix: str
        The suffix to add to the file name.
    :return: str
        The modified file path with the suffix added.

    :example:
    .. code-block:: python

        # Example usage of _add_suffix
        new_path = _add_suffix("example/file.txt", "_backup")
        # new_path would be "example/file_backup.txt"
    """
    path = path.rstrip("/")

    if not path.lower().endswith(".zarr"):
        logger.info(f"Added `{suffix}` extension to {path}")
        path += suffix
    return path


def _write_incomplete_file(path: str):
    fs, path = fsspec.url_to_fs(path)
    fs.makedirs(os.path.dirname(path), exist_ok=True)
    fs.touch(f"{path}.scallops")


@delayed
def _remove_incomplete_file_delayed(d: Delayed, path: str):
    fs, path = fsspec.url_to_fs(path)
    fs.rm(f"{path}.scallops")
    return d


def _to_parquet(df: dd.DataFrame, path: str, **kwargs):
    compute = kwargs.pop("compute", True)
    kwargs["compute"] = False
    _write_incomplete_file(path)
    parquet_delayed = df.to_parquet(path, **kwargs)
    rm_delayed = _remove_incomplete_file_delayed(parquet_delayed, path)
    if compute:
        return rm_delayed.compute()
    return rm_delayed


def is_scallops_zarr(url: str) -> bool:
    """Checks if the given URL points to a valid Zarr file created by scallops.

    :param url: str
        The URL or file path to check.
    :return: bool
        True if the file is a valid Zarr file, False otherwise.

    """
    try:
        g = zarr.open(url, mode="r")
        return "scallops" in g.attrs
    except:  # noqa: E722
        return False


def is_parquet_file(url: str) -> bool:
    """Checks if the given URL points to a valid Parquet file created by scallops.

    :param url: str
        The URL or file path to check.
    :return: bool
        True if the file is a valid Parquet file, False otherwise.

    :example:
    .. code-block:: python

        # Example usage of is_parquet_file
        is_valid = is_parquet_file("data/sample.parquet")
        # is_valid would be True if the file is a valid Parquet file
    """
    try:
        fs, url = fsspec.core.url_to_fs(url)
        ds = pq.ParquetDataset(url, filesystem=fs)
        return len(ds.schema.names) > 0 and not fs.exists(f"{url}.scallops")
    except:  # noqa: E722
        return False


def read_image(
    path: str | Path | zarr.Group,
    dask: bool = False,
    scene_id: None | str | int = None,
    tmp_dir: str | None = None,
    **kwargs,
) -> xr.DataArray:
    """Read a single image from various supported formats. This function reads image data from a
    single file or zarr group. It supports various file formats including tiff, nd2, and other Bio-
    Formats supported formats. The returned data is represented as a xarray DataArray with
    dimensions (t, c, z, y, x).

    To read a directory of images, see: :func:`~scallops.io.read_experiment`.

    :param path: Path to the image file or zarr group.
    :param dask: Whether the returned DataArray should be a dask or numpy array.
    :param scene_id: A valid scene id or index to read a specific scene from the image.
    :param tmp_dir: Temporary directory to save non-local nd2 files (default is None).
    :param kwargs: Additional arguments to pass to the bioio.BioImage constructor.
    :return: DataArray with the dimensions (t, c, z, y, x).

    :example:

    .. code-block:: python

        import scallops.io

        # Read an image
        image_path = "path/to/your/image.tiff"
        image = scallops.io.read_image(image_path)

        # Optionally, specify a scene id
        scene_id = 0
        image_with_scene = scallops.io.read_image(image_path, scene_id=scene_id)
    """
    return _read_image(path, dask, scene_id, tmp_dir, **kwargs)


def _localize_path(
    path: str, tmp_dir: str | None = None, suffixes: tuple[str] = (".nd2",)
) -> str | None:
    """Downloads non-local files. Typically used to download nd2 files as they must be
    read locally.

    :param path: Image path
    :param tmp_dir: Download path
    :param suffixes: Supported lowercase file extensions
    :return: Localized path or `None` if path suffix does not match provided suffixes.
    """

    suffix = os.path.splitext(path.lower())[1]
    if suffix in suffixes:
        fs, _ = fsspec.core.url_to_fs(path)
        if _get_fs_protocol(fs) != "file":
            # can not read non-local nd2 files
            return _download_file(fs, path, tmp_dir=tmp_dir, suffix=suffix)
    return None


def _create_image(path: str, **kwargs) -> bioio.BioImage:
    """Creates a BioImage object from a given file path with optional arguments.

    :param path: str
        The file path to the image.
    :param kwargs: dict
        Additional arguments to customize the BioImage creation.
    :return: bioio.BioImage
        The created BioImage object.

    :example:

    .. code-block:: python

        # Example usage of _create_image
        image = _create_image("data/sample_image.tiff", reconstruct_mosaic=True)
    """
    img_args = dict(reconstruct_mosaic=False)
    img_args.update(**kwargs)
    path_lc = path.lower()
    base_path_lc, ext = os.path.splitext(path_lc)
    if "reader" not in img_args:
        if ext in ["", ".zarr", "/", ".zarr/"]:
            img_args["reader"] = bioio_ome_zarr.Reader
        elif ext in [".tiff", ".tif"] and os.path.splitext(base_path_lc)[1] != ".ome":
            img_args["reader"] = bioio_tifffile.Reader
    return bioio.BioImage(path, **img_args)


def _download_file(fs, path, suffix=None, tmp_dir: str | None = None):
    """Downloads a file from a filesystem to a local temporary file.

    :param fs: filesystem object
        The filesystem object used to access the remote file.
    :param path: str
        The path to the file on the remote filesystem.
    :param tmp_dir: str, optional
        Download file to directory
    :param suffix: str, optional
        The suffix for the temporary file, usually the file extension (default is None).
    :return: str
        The local path to the downloaded file.

    :example:

    .. code-block:: python

        # Example usage of _download_file
        local_file = _download_file(fs, "remote/path/to/file.txt")
    """
    if suffix is None:
        suffix = os.path.splitext(path)[1]
    fd, local_path = tempfile.mkstemp(suffix=suffix, dir=tmp_dir)
    os.close(fd)
    fs.get(path, local_path)
    return local_path


def _read_image(
    path: str | zarr.Group | Path,
    dask: bool = False,
    scene_id: str = None,
    tmp_dir: str | None = None,
    **kwargs,
) -> xr.DataArray:
    """Reads an image from a given path or Zarr group into an xarray DataArray.

    :param path: str | zarr.Group
        The file path or Zarr group from which to read the image.
    :param dask: bool, optional
        Whether to use Dask for lazy loading of the image (default is False).
    :param scene_id: str, optional
        The ID of the specific scene to read from a multi-scene file (default is None).
    :param tmp_dir: str, optional
        Temporary directory to save non-local nd2 files (default is None).
    :param kwargs: dict
        Additional arguments passed to the image reading function.
    :return: xr.DataArray
        The image data as an xarray DataArray.

    :example:
    .. code-block:: python

        # Example usage of _read_image
        image = _read_image("path/to/image.tiff", dask=True, scene_id="Scene1")
    """
    if isinstance(path, Path):
        path = str(path)
    path_lc = path.lower() if not isinstance(path, zarr.Group) else path.name.lower()

    if (
        isinstance(path, zarr.Group)
        or path_lc.endswith(".zarr")
        or path_lc.endswith(".zarr/")
        or os.path.splitext(path_lc)[1] == ""
    ):
        return read_ome_zarr_array(path, dask)
    local_path = _localize_path(path, tmp_dir=tmp_dir)
    if local_path is not None:
        path = local_path
    img = _create_image(path, **kwargs)
    if scene_id is not None:
        img.set_scene(scene_id=scene_id)
    data = img.xarray_data if not dask else img.xarray_dask_data
    try:
        data.attrs["ome"] = img.ome_metadata.model_dump()
    except NotImplementedError:
        pass
    for c in ["Z", "Y", "X"]:
        if c in data.coords:
            del data.coords[c]
    data = data.rename({"T": "t", "C": "c", "Z": "z", "Y": "y", "X": "x"})
    if local_path is not None:
        atexit.register(lambda: os.remove(local_path))
    return data


def _read_in_situ_tables(path: str, pattern: None | str = None) -> pd.DataFrame:
    """Reads in-situ sequencing data tables from a given path, optionally filtering by a pattern.

    :param path: str
        The file path or directory containing the in-situ sequencing data tables.
    :param pattern: str, optional
        The pattern to match files within the directory (default is None, which matches all files).
    :return: pd.DataFrame
        The combined data from all matched tables as a pandas DataFrame.

    :example:

    .. code-block:: python

        # Example usage of _read_in_situ_tables
        data = _read_in_situ_tables("path/to/tables", pattern="*.csv")
    """
    results = []

    # read individually to add unique cell
    fs, _ = fsspec.core.url_to_fs(path)

    if pattern is None:
        pattern = "**"
    path = f"{path.rstrip(fs.sep)}{fs.sep}{pattern}"
    max_cell_id = 0

    paths = fs.glob(path)
    assert len(paths) > 0, "No files found"
    if _get_fs_protocol(fs) != "file":
        paths = [f"{_get_fs_protocol(fs)}://{x}" for x in paths]

    for p in paths:
        name = os.path.basename(p)
        if name[0] == ".":
            continue  # skip hidden files
        name = os.path.splitext(name)[0]
        path_lc = p.lower()
        df = None
        if path_lc.endswith(".parquet"):
            df = pq.read_pandas(p).to_pandas()
        elif path_lc.endswith(".csv") or path_lc.endswith(".csv.gz"):
            df = pd.read_csv(p)
        if df is not None:
            df["src"] = name
            if "label" not in df.columns and "cell" in df.columns:  # old results
                df = df.rename({"cell": "label"}, axis=1)
            df["unique_label"] = 0
            df.loc[df["label"] > 0, "unique_label"] = (
                df[df["label"] > 0]["label"] + max_cell_id
            )
            max_cell_id = max_cell_id + df["label"].max()
            results.append(df)
    result_df = pd.concat(results) if len(results) > 0 else pd.DataFrame()
    if "tile" in result_df.columns and not pd.api.types.is_numeric_dtype(
        result_df["tile"]
    ):
        result_df["tile"] = result_df["tile"].astype(int)
    return result_df


def read_in_situ_reads_and_barcodes(
    reads_directory: str,
    barcodes_path: str,
    barcode_indices: None | Sequence[int],
    reads_pattern: None | str,
) -> tuple[pd.DataFrame, pd.DataFrame]:
    """Load reads and barcodes information for in situ experiments. This function loads reads and
    barcodes information from the specified directories and files. It also matches reads with
    barcodes and adds a 'barcode_match' column to the reads DataFrame.

    :param reads_directory: Path to the directory containing reads information.
    :param barcodes_path: Path to the file containing barcodes information.
    :param barcode_indices: Optional list of indices (0-based) to extract from the barcode column.
    :param reads_pattern: Optional pattern to filter read paths.
    :return: Tuple containing DataFrames for reads and barcodes.

    :example:

    .. code-block:: python

        import scallops.io

        # Define paths and parameters
        reads_directory = "path/to/reads/directory"
        barcodes_path = "path/to/barcodes/file.csv"
        barcode_indices = [
            0,
            1,
            2,
        ]  # Optional list of indices to extract from the barcode column
        reads_pattern = "*.csv"  # Optional pattern to filter read paths

        # Load reads and barcodes
        reads, barcodes = scallops.io.read_in_situ_reads_and_barcodes(
            reads_directory, barcodes_path, barcode_indices, reads_pattern
        )

        # Display loaded data
        print("Reads DataFrame:")
        print(reads.head())
        print("\nBarcodes DataFrame:")
        print(barcodes.head())
    """
    reads_df = _read_in_situ_tables(reads_directory, pattern=reads_pattern)
    if barcode_indices is None:
        barcode_indices = np.arange(0, reads_df["barcode"].str.len().max(), dtype=int)
    barcodes_df = read_barcodes(barcodes_path, barcode_indices)

    reads_df["barcode_match"] = reads_df["barcode"].isin(barcodes_df["barcode"])
    return reads_df, barcodes_df


def save_ome_tiff(
    data: np.ndarray | xr.DataArray | da.Array,
    uri: str,
    dim_order: str | list[str | None] | None = None,
    compute: bool = True,
    attrs: Mapping[str, Any] | None = None,
    ome_xml: str | OME = None,
) -> list[Delayed]:
    """Save array to OME-TIFF format.

    This function saves the input data to an OME-TIFF file. If the specified URI is
    not local, the data is first written to a temporary file
    and then moved to the specified URI.

    :param data: The data to save.
    :param uri: URI to save the OME-TIFF file to.
    :param dim_order: Order of the dimensions.
    :param compute: If true compute immediately otherwise a list
        of :class:`dask.delayed.Delayed` is returned.
    :return: Empty list if the compute flag is True, otherwise it returns a list of
        :class:`dask.delayed.Delayed` representing the value to be computed by dask.
    :param attrs: Key-values to save as map attributes

    Example:

    .. code-block:: python

        import scallops.io
        import numpy as np

        # Create some example data
        data = np.random.rand(10, 512, 512)

        # Save the data to an OME-TIFF file
        uri = "path/to/save/file.ome.tiff"
        scallops.io.save_ome_tiff(data, uri)
    """
    data = data.data if isinstance(data, xr.DataArray) else data
    if isinstance(data, da.Array) and not compute:
        _save_ome_tiff_delayed = dask.delayed(_save_ome_tiff)
        return _save_ome_tiff_delayed(
            data=data, uri=uri, dim_order=dim_order, attrs=attrs, ome_xml=ome_xml
        )
    _save_ome_tiff(
        data=data, uri=uri, dim_order=dim_order, attrs=attrs, ome_xml=ome_xml
    )
    return []


def _save_ome_tiff(
    data: np.ndarray,
    uri: str,
    dim_order: str | list[str | None] | None = None,
    attrs: Mapping[str, Any] | None = None,
    ome_xml: str | OME = None,
):
    """Saves image data to an OME-TIFF file.

    :param data: The image data to be saved.
    :param uri: The file path or URI where the OME-TIFF file will be saved.
    :param dim_order: The dimension order of the data (e.g., "XYZCT").
        If None, it's inferred from the DataArray (default is None).
    :param attrs: Key-values to save as map attributes
    :params ome_xml: Optional OME metadata

    :example:
    .. code-block:: python

        # Example usage of _save_ome_tiff
        _save_ome_tiff(image_data, "output.ome.tiff", dim_order="XYZCT")
    """
    if dim_order is None and isinstance(data, xr.DataArray):
        dim_order = "".join([str(d).upper() for d in data.dims])
    fs, _ = fsspec.core.url_to_fs(uri)
    local_path = uri

    if _get_fs_protocol(fs) != "file":
        # can not write non-local tiff files
        fd, local_path = tempfile.mkstemp(suffix=".tiff")
        os.close(fd)

    if attrs is not None:
        import bioio_base as biob

        if ome_xml is None:
            ome_xml = OmeTiffWriter.build_ome(
                [data.shape],
                [data.dtype],
                channel_names=[None],
                image_name=[None],
                physical_pixel_sizes=[biob.types.PhysicalPixelSizes(None, None, None)],
                channel_colors=[None],
                dimension_order=[dim_order],
            )
        ome_xml.structured_annotations.append(MapAnnotation(value=attrs))
        # ome_xml.structured_annotations.append(
        #     TagAnnotation(value='', description=''))
    OmeTiffWriter.save(
        data=data,
        dim_order=dim_order,
        uri=local_path,
        ome_xml=ome_xml,
    )
    if _get_fs_protocol(fs) != "file":
        fs.put(local_path, uri)
        os.remove(local_path)


def read_barcodes(
    barcodes_path: str,
    barcode_indices: None | Sequence[int],
    barcode_column: str = "barcode",
) -> pd.DataFrame:
    """Load barcodes from a CSV file.

    This function reads barcodes from a CSV file. It optionally allows selecting specific
    indices from the barcode column. It performs validation to ensure all barcodes have
    the same length.

    :param barcodes_path: Path to the CSV file containing barcodes.
    :param barcode_indices: Optional list of indices (0-based) to extract from the barcode column.
    :param barcode_column: Name of the barcode column in the CSV file.
    :return: DataFrame containing the loaded barcodes.

    :example:

    .. code-block:: python

        import scallops.io

        # Define the path to the barcodes CSV file
        barcodes_path = "path/to/barcodes.csv"

        # Load barcodes without selecting specific indices
        barcodes_df = scallops.io.read_barcodes(barcodes_path)
        print(barcodes_df.head())

        # Load barcodes and select specific indices
        selected_indices = [0, 1, 2]
        barcodes_df_selected = scallops.io.read_barcodes(
            barcodes_path, barcode_indices=selected_indices
        )
        print(barcodes_df_selected.head())
    """
    barcodes_df = pd.read_csv(barcodes_path)
    if barcode_column != "barcode":
        rename = {barcode_column: "barcode"}
        barcodes_df = barcodes_df.rename(rename, axis=1)

    if barcode_indices is not None and len(barcode_indices) > 0:
        _barcodes = barcodes_df["barcode"]
        barcodes = ""
        for i in barcode_indices:
            barcodes += _barcodes.str[i]
    else:
        barcodes = barcodes_df["barcode"]
    barcodes_df["barcode"] = barcodes
    barcode_len = len(barcodes_df["barcode"].iloc[0])
    indices = np.where(barcodes_df["barcode"].str.len() != barcode_len)[0]
    n_wrong_len = len(indices)
    if n_wrong_len > 0:
        max_indices = indices[:10]
        wrong_len_barcodes = ",".join(barcodes_df.iloc[max_indices])
        if len(max_indices) != len(indices):
            wrong_len_barcodes += (
                f", and {len(wrong_len_barcodes) - len(indices)} more."
            )
        raise ValueError(
            f"Found {n_wrong_len} barcode{'s' if n_wrong_len > 1 else ''} not having expected length of {barcode_len}: {wrong_len_barcodes}"
        )
    return barcodes_df


def to_image_montage(
    experiment: Experiment,
    keys: list[str],
    path: str,
    crop: int | tuple[int, int, int, int] = None,
    **kwargs,
):
    """Create an image montage using the image keys from the specified experiment.

    This function creates an image montage by arranging images corresponding to the given keys
    from the specified experiment. The montage is saved to a TIFF file.

    :param experiment: The experiment containing images.
    :param keys: List of image keys to include in the montage.
    :param path: Path to the output TIFF file.
    :param crop: Pixel size for cropping each panel at the center (e.g., crop=300 means only show
                 a 300x300 area at the center) or tuple of (x, y, width, height).
    :param kwargs: Additional arguments to pass to tifffile.imwrite. For example, imagej=True.

    :example:

    .. code-block:: python

        import scallops.io
        from scallops.experiment.elements import Experiment

        # Create an experiment object (assuming it's defined somewhere)
        experiment = Experiment(...)

        # Define image keys and path to save montage
        keys = ["image1", "image2", "image3"]
        montage_path = "path/to/montage.tiff"

        # Create an image montage and save it to a TIFF file
        scallops.io.to_image_montage(experiment, keys, montage_path)
    """
    image_arrange = int(np.ceil(np.sqrt(len(keys))))
    image0 = experiment.images[keys[0]].squeeze()
    if crop is not None:
        image0 = _crop(image0, crop)
    dtype = image0.dtype
    tile_size_y = image0.sizes["y"]
    tile_size_x = image0.sizes["x"]

    image0_shape = image0.shape
    image_shape = list(image0.shape)
    image_shape[-2] *= image_arrange
    image_shape[-1] *= image_arrange
    image_shape = tuple(image_shape)
    axes = "".join(image0.dims).upper()
    metadata = {"axes": axes}
    image_args = dict(
        shape=image_shape, dtype=dtype, photometric="minisblack", tile=(1024, 1024)
    )
    image_args.update(kwargs)
    if "c" in image0.coords:
        metadata["Channel"] = {"Name": image0.coords["c"].values.tolist()}
    tifffile.imwrite(
        path,
        **image_args,
        metadata=metadata,
    )
    with tifffile.imread(path, mode="r+", aszarr=True) as store:
        array = zarr.open(store, mode="r+")

        for i, j in product(range(image_arrange), repeat=2):
            index = i * image_arrange + j
            if index < len(keys):
                image = experiment.images[keys[index]].squeeze()
                if crop is not None:
                    image = _crop(image, crop)
                values = image.values
                assert values.shape == image0_shape

                if len(image0_shape) > 2:
                    array[
                        :,
                        i * tile_size_y : i * tile_size_y + tile_size_y,
                        j * tile_size_x : j * tile_size_x + tile_size_x,
                    ] = values
                else:
                    array[
                        i * tile_size_y : i * tile_size_y + tile_size_y,
                        j * tile_size_x : j * tile_size_x + tile_size_x,
                    ] = values


def get_pixel_positions(path: str) -> np.ndarray:
    """Gets the stage pixel positions from the image at the specified path.

    This function extracts stage pixel positions from the metadata of an image file located at the specified path.
    It returns an array with the pixel positions assuming that the image file contains said metadata.

    :param path: Path to the image file.
    :return: Array with pixel positions.

    :example:

    .. code-block:: python

        import scallops.io
        import numpy as np

        # Define the path to the image file
        image_path = "path/to/image.nd2"

        # Get pixel positions from the image
        positions = scallops.io.get_pixel_positions(image_path)
        print(positions)
    """
    local_path = None
    if path.endswith(".nd2"):
        fs, _ = fsspec.core.url_to_fs(path)
        if _get_fs_protocol(fs) != "file":
            # can not read non-local nd2 files
            fd, local_path = tempfile.mkstemp(suffix=".nd2")
            os.close(fd)
            fs.get(path, local_path)
            path = local_path

    img = bioio.BioImage(path, reconstruct_mosaic=False)
    pixels = img.ome_metadata.images[0].pixels
    plane = pixels.planes[0]

    position_microns = np.array([plane.position_y, plane.position_x], dtype=float)
    # Invert Y so that stage position coordinates and image pixel coordinates are aligned

    position_microns *= [-1, 1]
    position_pixels = position_microns / [
        pixels.physical_size_y,
        pixels.physical_size_x,
    ]
    if local_path is not None:
        os.remove(local_path)
    return position_pixels


def physical_coords_to_px(
    coords: tuple[float, float], physical_size: tuple[float, float]
) -> tuple[int, int]:
    """Convert physical coordinates to pixel coordinates.

    :param coords: Physical coordinates
    :param physical_size: Tuple of micrometers per pixel
    :return: Pixel coordinates
    """
    # physical_size = um/px

    return int(np.round(coords[0] / physical_size[0])), int(
        np.round(coords[1] / physical_size[1])
    )


def read_experiment(
    image_path: str | Path | list[str | Path],
    files_pattern: str | re.Pattern | None = None,
    group_by: tuple[str, ...] = ("well", "tile"),
    subset: Callable[[str], bool] | Sequence[str | re.Pattern] | None = None,
    dask: bool = False,
    scenes: bool | list[str] = False,
    **kwargs,
) -> Experiment:
    """Read in an experiment from a directory of tiff, nd2, other Bio-Formats supported images or a
    zarr file.

    If the file pattern contains `c` or `t`, images belonging to the same group will be stacked along these dimensions.

    :param image_path: Path(s) to search for images
    :param files_pattern: pattern of the image. For example, {mag}X_c{t}-{skip}_{well}_Tile-{tile}.{data_type}.tif.
                          Ignored if input is in zarr format.
    :param group_by: Groups (in `files_pattern`) to group by. Ignored if input is in zarr format.
    :param subset: Image keys to include. Use * for wildcard. For example A2-* will include all tiles in well A2.
    :param dask: Whether image in image DataArray is dask or numpy array
    :param scenes: Whether to read all scenes in an image or a list of scene ids
    :param kwargs: Additional arguments to pass to bioio.BioImage constructor
    :return: Experiment mapping keys to images. Each image has the dimensions (t,c,z,y,x).
    """
    if not isinstance(image_path, list):
        image_ext = os.path.splitext(str(image_path).lower())[1].rstrip("/")
        if image_ext == ".zarr":
            return _read_zarr_experiment(
                image_path, dask, _create_subset_function(subset)
            )
    images = {}

    for group, file_list, metadata in _set_up_experiment(
        image_path, files_pattern, group_by, subset, scenes
    ):
        images[metadata["id"]] = _LazyLoadImage(
            file_list, metadata, dask, metadata.get("scene_id"), **kwargs
        )
    return Experiment(images)


def _match_size(images: list[xr.DataArray], fill_value: float = None):
    """Ensure all the images are the same size.

    Images in an image stack might be slightly different sizes due to stitching differences
    :param: images: List of images
    :param: fill_value: Value to pad with of `None` to use image min value
    """
    y_sizes = set()
    x_sizes = set()
    for image in images:
        y_sizes.add(image.sizes["y"])
        x_sizes.add(image.sizes["x"])
    if len(y_sizes) > 1 or len(x_sizes) > 1:
        image_size_y = np.max(list(y_sizes))
        image_size_x = np.max(list(x_sizes))

        for i in range(len(images)):
            image = images[i]
            delta_y = image_size_y - image.sizes["y"]
            delta_x = image_size_x - image.sizes["x"]
            pad = dict()
            image = image.drop_vars(["x", "y"], errors="ignore")
            if delta_y > 0 or delta_x > 0:
                if delta_y > 0:
                    pad["y"] = (delta_y, 0)
                if delta_x > 0:
                    pad["x"] = (delta_x, 0)
                image = image.pad(
                    pad,
                    constant_values=fill_value
                    if fill_value is not None
                    else image.min(),
                    mode="constant",
                    keep_attrs=True,
                )
                images[i] = image
        return True
    return False


def _get_processed_spacing(attrs: dict) -> tuple[float, float] | None:
    """Retrieves the processed image spacing (physical size) from the provided attributes.

    :param attrs: dict
        The attributes containing the processed image metadata.
    :return: tuple[float, float] | None
        A tuple containing the physical size in the Y and X dimensions, or None if not available.

    :example:
    .. code-block:: python

        # Example usage of _get_processed_spacing
        spacing = _get_processed_spacing(attrs)
    """
    spacing = None
    ome = attrs["processed"]

    if isinstance(ome, str):
        try:
            ome = ome_types.from_xml(ome)
        except ValueError:
            return None

    if isinstance(ome, OME):
        spacing = (
            ome.images[0].pixels.physical_size_y,
            ome.images[0].pixels.physical_size_x,
        )
    elif "images" in ome:  # dict
        spacing = (
            ome["images"][0]["pixels"]["physical_size_y"],
            ome["images"][0]["pixels"]["physical_size_x"],
        )

    return spacing


def _extract_crops(
    intensity_image: np.ndarray | zarr.Array,
    label_image: np.ndarray | zarr.Array | None,
    objects_df: pd.DataFrame,
    query: str,
    sl: tuple[slice],
    output_dir: str,
    output_format: Literal["tiff", "npy"],
    gaussian_sigma: float | None,
):
    objects_df = objects_df.query(query)
    labels = objects_df.index.values
    # global coordinates
    bbox0 = objects_df["bbox-0"].values
    bbox2 = objects_df["bbox-2"].values
    bbox1 = objects_df["bbox-1"].values
    bbox3 = objects_df["bbox-3"].values

    if isinstance(intensity_image, np.ndarray):
        bbox0 = bbox0 - sl[0].start
        bbox2 = bbox2 - sl[0].start
        bbox1 = bbox1 - sl[1].start
        bbox3 = bbox3 - sl[1].start
    fs = fsspec.core.url_to_fs(output_dir)[0]
    protocol = _get_fs_protocol(fs)
    for i in range(len(objects_df)):
        label = labels[i]
        y, x = (slice(bbox0[i], bbox2[i]), slice(bbox1[i], bbox3[i]))
        img = intensity_image[..., y, x]
        if label_image is not None:
            img_type = img.dtype
            label_mask = label_image[y, x] == label
            if gaussian_sigma is not None:
                # apply gaussian-smoothed mask to isolate target cell
                label_mask = gaussian_filter(
                    label_mask.astype(float), sigma=gaussian_sigma
                )
                if label_mask.max() > 0:
                    label_mask = label_mask / label_mask.max()
            img = (img * label_mask).astype(img_type, copy=False)
        if output_format == "tiff":
            with (
                fs.open(f"{output_dir}/{label}.tiff", "wb") as f,
                tifffile.TiffWriter(f) as tif,
            ):
                tif.write(img, compression="zlib")
        else:
            if protocol == "file":
                np.save(f"{output_dir}/{label}.npy", img)
            else:
                bytes_buffer = BytesIO()
                np.save(bytes_buffer, img)
                bytes_buffer.seek(0)
                with fs.open(f"{output_dir}/{label}.npy", "wb") as f:
                    f.write(bytes_buffer.getvalue())


def to_label_crops(
    intensity_image: zarr.Array | da.Array,
    label_image: zarr.Array | da.Array | None,
    objects_df: pd.DataFrame,
    output_dir: str,
    crop_size: tuple[int, int] = (224, 224),
    output_format: Literal["tiff", "npy"] = "tiff",
    centroid_cols: Sequence[str] | None = None,
    gaussian_sigma: float | None = None,
) -> pd.DataFrame:
    """Export individual label crops as tiff or npy files.

    :param intensity_image: Image data
    :param label_image: Label data. If supplied, image is masked by corresponding segmentation mask
    :param objects_df: DataFrame containing objects from `find-objects`.
    :param crop_size: Size of label crop
    :param output_dir: Crop output directory
    :param output_format: Crop output format
    :param centroid_cols: Columns in objects_df containing y and x centroids.
    :param gaussian_sigma: If not None, apply gaussian-smoothed mask to isolate target mask
    :return: Objects dataframe (with objects at well edges removed)
    """
    assert not isinstance(objects_df.index, pd.RangeIndex), (
        "Index should contain `label`"
    )
    is_dask_array = isinstance(intensity_image, da.Array)
    image_shape = intensity_image.shape[-2:]
    if label_image is not None:
        assert label_image.shape == image_shape, (
            "Label shape does not match image shape."
        )
        assert isinstance(label_image, da.Array) == is_dask_array, (
            "Label image type does not match intensity image type."
        )
        if is_dask_array and intensity_image.chunksize[-2:] != label_image.chunks:
            label_image = label_image.rechunk(intensity_image.chunksize[-2:])

    fs, _ = fsspec.url_to_fs(output_dir)
    fs.makedirs(output_dir, exist_ok=True)
    if centroid_cols is None:
        centroid_cols = objects_df.columns[
            objects_df.columns.str.contains("AreaShape_Center_Y")
            | objects_df.columns.str.contains("AreaShape_Center_X")
        ]
        assert len(centroid_cols) == 2, "Unable to infer centroid columns."
        centroid_cols = sorted(centroid_cols, reverse=True)  # y before x

    centroid_cols = list(centroid_cols)
    objects_df = objects_df[centroid_cols].copy()
    crop1 = crop_size[0] // 2
    crop2 = math.ceil(crop_size[0] / 2)

    for c in centroid_cols:
        objects_df[c] = objects_df[c].round().astype(int)

    objects_df["bbox-0"] = objects_df[centroid_cols[0]] - crop1
    objects_df["bbox-2"] = objects_df[centroid_cols[0]] + crop2

    crop1 = crop_size[1] // 2
    crop2 = math.ceil(crop_size[1] / 2)
    objects_df["bbox-1"] = objects_df[centroid_cols[1]] - crop1
    objects_df["bbox-3"] = objects_df[centroid_cols[1]] + crop2

    n_objects = len(objects_df)
    # filter small objects at well edge
    objects_df = objects_df.query(
        f"`bbox-0`>=0 & `bbox-2` <={image_shape[0]} "
        f"& `bbox-1`>=0 & `bbox-3` <={image_shape[1]}"
    )
    n_objects_filtered = len(objects_df)

    if n_objects_filtered < n_objects:
        logger.info(
            f"Removed {n_objects - n_objects_filtered:,} {pluralize('label', n_objects - n_objects_filtered)}"
        )

    chunk_slices = da.core.slices_from_chunks(
        intensity_image.chunks[-2:]
        if is_dask_array
        else da.from_zarr(intensity_image).chunks[-2:]
    )
    results = []
    _extract_crops_delayed = delayed(_extract_crops)

    if not is_dask_array:
        intensity_image = delayed(intensity_image)
        if label_image is not None:
            label_image = delayed(label_image)
    objects_df_delayed = delayed(objects_df)
    for sl in chunk_slices:
        array_start = [s.start for s in sl]
        array_end = [s.stop for s in sl]
        query = f"{array_start[0]}<=`bbox-0`<{array_end[0]} & {array_start[1]}<=`bbox-1`<{array_end[1]}"
        objects_df_slice = objects_df.query(query)
        if len(objects_df_slice) > 0:
            sl = (
                slice(
                    objects_df_slice["bbox-0"].min(),
                    objects_df_slice["bbox-2"].max(),
                ),
                slice(
                    objects_df_slice["bbox-1"].min(),
                    objects_df_slice["bbox-3"].max(),
                ),
            )
            label_block = None
            if is_dask_array:
                image_block = intensity_image[..., sl[0], sl[1]]
                if label_image is not None:
                    label_block = label_image[sl[0], sl[1]]

            results.append(
                _extract_crops_delayed(
                    intensity_image=image_block if is_dask_array else intensity_image,
                    label_image=label_block if is_dask_array else label_image,
                    output_dir=output_dir,
                    sl=sl,
                    query=query,
                    output_format=output_format,
                    objects_df=objects_df_delayed,
                    gaussian_sigma=gaussian_sigma,
                )
            )
    dask.compute(*results)
    return objects_df


def example_image_coords(
    image: xr.DataArray,
    padding: float = 0.3,
    spacing: tuple[float, float] | None = None,
) -> list[tuple[int, int]]:
    """Create a list of example image coordinates.

    :param image: The image
    :param padding: Padding from image center
    :param spacing: Optional image spacing
    :return: List of coordinates
    """
    if spacing is None:
        spacing = (1, 1)
    size_y = image.sizes["y"] * spacing[0]
    size_x = image.sizes["x"] * spacing[1]
    y_start = int(size_y * padding)
    x_start = int(size_x * padding)
    y_end = int(size_y - size_y * padding)
    x_end = int(size_x - size_x * padding)

    coords = [
        (int(size_y / 2), int(size_x / 2)),
        (y_start, x_start),
        (y_start, x_end),
        (y_end, x_end),
        (y_end, x_start),
    ]
    return coords


def get_image_spacing(attrs: dict) -> tuple[float, float] | None:
    """Get the physical spacing (resolution) of an image.

    This function retrieves the physical spacing (resolution) of an image from its attributes.
    The spacing is typically defined in micrometers per pixel (µm/pixel) along the y and x dimensions.

    :param attrs: Dictionary containing image attributes.
    :return: A tuple containing the spacing along the y and x dimensions in micrometers (µm).
             Returns None if the spacing cannot be determined.

    Example:

    .. code-block:: python

        import scallops.io

        # Define image attributes
        attrs = {
            "processed": OME,
            "src_metadata": [
                {"attrs": {"processed": OME}},
                {"attrs": {"processed": OME}},
                {"attrs": {"processed": OME}},
            ],
        }

        # Get the image spacing
        spacing = scallops.io.get_image_spacing(attrs)
        print(spacing)  # Output: (0.25, 0.25)
    """
    spacing = None
    if "processed" in attrs:
        spacing = _get_processed_spacing(attrs)
    if spacing is None and "src_metadata" in attrs:
        src_metadata = attrs["src_metadata"]
        attrs_0 = src_metadata[0]["attrs"]

        if "processed" in attrs_0:
            spacing = _get_processed_spacing(attrs_0)

            if spacing is not None:
                spacing_equal = True
                for i in range(1, len(src_metadata)):
                    attrs_i = src_metadata[i]["attrs"]
                    if "processed" in attrs_i:
                        spacing_i = _get_processed_spacing(attrs_i)
                        if (spacing_i is None) or (spacing_i != spacing):
                            spacing_equal = False
                    else:
                        spacing_equal = False
                    if not spacing_equal:
                        break
                if spacing_equal:
                    return spacing
    if spacing is None and "physical_pixel_sizes" in attrs:
        return attrs["physical_pixel_sizes"]
    return spacing


def _combine_attrs(variable_attrs: Sequence[Dict], context: str | None = None) -> Dict:
    """Combines multiple attribute dictionaries into a single dictionary, handling conflicts.

    :param variable_attrs: Sequence[Dict]
        A sequence of attribute dictionaries to be combined.
    :param context: Optional[str], optional
        The context for combining attributes (default is None).
    :return: Dict
        A dictionary containing the combined attributes.

    :example:
    .. code-block:: python

        # Example usage of _combine_attrs
        combined_attrs = _combine_attrs([attrs1, attrs2])
    """
    result = {}
    dropped_keys = set()

    for attrs in variable_attrs:
        result.update(
            {
                key: value
                for key, value in attrs.items()
                if key not in result and key not in dropped_keys
            }
        )
        for key, value in result.items():
            try:
                if key not in attrs or equivalent(attrs[key], value):
                    # ignore errors comparing equality (e.g. `dict(a=np.ones(3)) == dict(a=np.ones(3))`)
                    result[key] = value
            except:  # noqa: E722
                pass

        dropped_keys |= {key for key in attrs if key not in result}
    return result


def _images2fov(
    file_list: list[str] | zarr.Group,
    attrs: dict[str, str | list[str]] | None,
    dask: bool = False,
    scene_id: str = None,
    concat_dims: tuple[str] = ("z", "c", "t"),
    tmp_dir: str | None = None,
    **kwargs,
) -> xr.DataArray | list[xr.DataArray]:
    """Converts a list of image files or a Zarr group into a field of view (FOV)
    represented as a DataArray.

    :param file_list: List of file paths or a Zarr group containing the images.
    :param attrs: Attributes containing metadata for the images.
    :param dask: Whether to use Dask for lazy loading of the images (default is False).
    :param scene_id: ID of the specific scene to read from a multi-scene file (default is None).
    :param concat_dims: Dimensions along which to concatenate the images.
    :param tmp_dir: Temporary directory to save non-local nd2 files (default is None).
    :param kwargs: Additional arguments passed to the image processing functions.
    :return: The images as a field of view represented as a DataArray, or a list of
        DataArrays if concatenation is not possible.

    :example:
    .. code-block:: python

        # Example usage of _images2fov
        fov = _images2fov(
            file_list=["image1.tiff", "image2.tiff"], attrs=metadata, dask=True
        )
    """
    if isinstance(file_list, zarr.Group):
        file_list = [file_list]

    images = []

    file_metadata = attrs.get("file_metadata") if attrs is not None else None
    group_metadata = attrs.get("group_metadata", {}) if attrs is not None else {}

    if concat_dims is None:
        concat_dims = ()

    # e.g. concat by c and t if present in attrs and more than one image file
    if file_metadata is not None:
        concat_dims = [c for c in concat_dims if c in file_metadata[0]]
    image_attrs = []

    for i in range(len(file_list)):
        url = file_list[i]

        image = _read_image(
            url, dask=dask, scene_id=scene_id, tmp_dir=tmp_dir, **kwargs
        )
        if image is None:
            raise ValueError(f"{file_list[i]} could not be read.")
        if file_metadata is not None:
            if "t" in file_metadata[i] and isinstance(
                file_metadata[i]["t"], str
            ):  # convert to int
                try:
                    # note we replace "_" with "-" so we don't convert "1_2" to 12 e.g.
                    file_metadata[i]["t"] = int(file_metadata[i]["t"].replace("_", "-"))
                except ValueError:
                    # conversion to int failed
                    pass
            image.attrs.update(file_metadata[i])
        image_attrs.append(image.attrs.copy())

        coords = dict()
        ensure_dims = ["c", "t"]
        if "z" in concat_dims:
            ensure_dims.append("z")
        for d in ensure_dims:
            if file_metadata is not None and d in file_metadata[i]:
                if d not in image.dims:
                    axis = 0
                    if d == "t":
                        axis = 0
                    elif d == "c":
                        axis = 1 if "t" in image.dims else 0
                    elif d == "z":
                        if "c" in image.dims:
                            axis = image.dims.index("c") + 1
                        elif "t" in image.dims:
                            axis = 1
                    image = image.expand_dims(d, axis=axis)
                    logger.debug(f"Added dimension {d}")
                coords[d] = [file_metadata[i][d]]
        image = image.assign_coords(coords)
        images.append(image)

    if len(images) > 1:
        fill_value = 0
        for image in images:
            if np.issubdtype(image.dtype, np.floating):
                fill_value = np.nan
                break
        concat_dims = [
            dim
            for dim in concat_dims
            if len(set([image.coords[dim].values[0] for image in images])) > 1
        ]
        if len(concat_dims) > 0:
            _match_size(images)
        if len(concat_dims) == 1:
            image = xr.concat(
                images,
                dim=concat_dims[0],
                join="outer",
                fill_value=fill_value,
                combine_attrs=_combine_attrs,
            )
        elif len(concat_dims) > 1:
            # for example, concat 1st by channel matching on time, then concat again by time
            for concat_dim_index in range(len(concat_dims)):
                concat_dim = concat_dims[concat_dim_index]
                other_dims = []
                for j in range(concat_dim_index + 1, len(concat_dims)):
                    other_dims.append(concat_dims[j])
                group_2_images = defaultdict(list)
                for i in range(len(images)):
                    key = []
                    for dim in other_dims:
                        key.append(tuple(images[i].coords[dim].values))
                    key = tuple(key)
                    group_2_images[key].append(images[i])
                _images = []
                for image_group in group_2_images:
                    group_images = group_2_images[image_group]
                    image = xr.concat(
                        group_images,
                        dim=concat_dim,
                        join="outer",
                        fill_value=fill_value,
                        combine_attrs=_combine_attrs,
                    )
                    _images.append(image)
                images = _images
            assert len(images) == 1
            image = images[0]
        else:
            for i in range(len(images)):
                image = images[i]
                if group_metadata is not None:
                    image.attrs.update(group_metadata)
                image.attrs.update(image_attrs[i])
            return images
    else:
        image = images[0]
    if group_metadata is not None:
        image.attrs.update(group_metadata)
    if len(file_list) == 1:
        image.attrs.update(image_attrs[0])
    else:
        src_metadata = []
        image.attrs["src_metadata"] = src_metadata

        for i in range(len(file_list)):
            name = (
                os.path.basename(file_list[i])
                if not isinstance(file_list[i], zarr.Group)
                else _get_store_path(file_list[i])
            )
            src_metadata.append(dict(attrs=image_attrs[i], name=name))

        if "t" in image.coords:
            assert len(image.coords["t"].values) == len(
                set(image.coords["t"].values)
            ), 'Duplicate "t" dimension'
    if "c" in image.coords:
        assert len(image.coords["c"].values) == len(set(image.coords["c"].values)), (
            'Duplicate "c" dimension'
        )

    return image


def _create_file_regex(
    files_pattern: str, flags: int = re.IGNORECASE
) -> tuple[re.Pattern[str], str, KeysView[str]]:
    """Creates a greedy regular expression pattern from a file naming pattern.

    :param files_pattern: The file naming pattern containing placeholders for
        variable parts.
    :return: Regular expression, file suffix, and keys in pattern.

    :example:
    .. code-block:: python

        # Example usage of _create_file_regex
        regex, suffix, keys = _create_file_regex("image_{channel}_{z:03d}.tiff")
    """

    d = {}
    skip = {"ignore", "skip"}
    default_quantifier = "+"
    reformatted_pattern = []
    unique_field_names = set()
    for v in Formatter().parse(files_pattern):
        # literal_text, field_name, format_spec, conversion
        literal_text = v[0]
        field_name = v[1]
        format_spec = v[2]
        quantifier = default_quantifier
        if literal_text != "":
            reformatted_pattern.append(literal_text)

        if format_spec is not None and format_spec != "":
            quantifier = format_spec

            try:
                quantifier = f"{{{int(quantifier)}}}"
            except ValueError:
                pass
        if field_name is not None:
            is_skip = field_name in skip
            if field_name in unique_field_names:
                counter = 1
                base_field_name = field_name
                while field_name in unique_field_names:
                    field_name = f"{base_field_name}_{counter}"
                    counter += 1
            unique_field_names.add(field_name)
            reformatted_pattern.append("{" + field_name + "}")
            if is_skip:
                d[field_name] = f"(?:.{quantifier})"
            else:
                d[field_name] = f"(?P<{field_name}>.{quantifier})"
    reformatted_pattern = "".join(reformatted_pattern)

    if len(d) > 0:
        file_regex = re.compile(
            reformatted_pattern.replace(".", "\\.").format(**d), flags=flags
        )
    else:
        file_regex = re.compile(
            reformatted_pattern if reformatted_pattern != "*" else ".*", flags=flags
        )
    return file_regex, Path(reformatted_pattern).suffix.lower(), d.keys()


def _create_subset_function(
    subset: Callable[[str], bool] | Sequence[str | re.Pattern] | None = None,
    flags=re.IGNORECASE,
):
    """Creates a subset function based on the provided subset parameter.

    :param subset: A callable function to filter the subset, or a sequence of strings
        or patterns.
    :return: A function that takes a string and returns a boolean indicating if it
        belongs to the subset.

    :example:
    .. code-block:: python

        # Example usage of _create_subset_function
        subset_func = _create_subset_function(["channel1", "channel2"])
    """
    if isinstance(subset, Callable):
        return subset
    funcs = None

    def _create_func(s):
        if isinstance(s, re.Pattern):
            return lambda x: s.fullmatch(x)
        elif s.find("*") != -1:
            s = re.compile(s.replace("*", ".*"), flags=flags)
            return lambda x: s.fullmatch(x)
        else:
            return lambda x: s == x

    if subset is not None and len(subset) > 0:
        funcs = [_create_func(s) for s in subset]

    def _subset_include(x):
        if funcs is not None:
            # match at least one entry
            for f in funcs:
                if f(x):
                    return True
            return False
        else:
            return True

    return _subset_include


def read_anndata_zarr(store: StoreLike, dask: bool = False) -> anndata.AnnData:
    """Read from a hierarchical Zarr array store.

    :param store: Store to read from.
    :param dask: Whether to use dask.
    :return: AnnData object.
    """

    if not dask:
        return anndata.read_zarr(store)

    f = zarr.open(store, mode="r")

    def callback(func, elem_name: str, elem, iospec):
        if iospec.encoding_type in (
            "dataframe",
            "csr_matrix",
            "csc_matrix",
            "awkward-array",
        ):
            # Preventing recursing inside of these types
            return read_elem(elem)
        elif iospec.encoding_type == "array":
            return da.from_zarr(elem)
        else:
            return func(elem)

    return read_dispatched(f, callback=callback)


def _get_fs_protocol(fs: fsspec.AbstractFileSystem) -> str:
    """Retrieves the protocol used by the filesystem object.

    :param fs: fsspec.AbstractFileSystem
        The filesystem object from which to retrieve the protocol.
    :return: str
        The protocol used by the filesystem (e.g., "s3", "file").

    :example:
    .. code-block:: python

        # Example usage of _get_fs_protocol
        protocol = _get_fs_protocol(fs)
    """
    return fs.protocol[0] if isinstance(fs.protocol, (tuple, list)) else fs.protocol


def _set_up_experiment(
    image_path: str | Path | zarr.Group | Sequence[str | Path | zarr.Group],
    files_pattern: str | re.Pattern = "*",
    group_by: Sequence[str] = (),
    subset: Callable[[str], bool] | Sequence[str | re.Pattern] | None = None,
    scenes: bool | list[str] = False,
    file_sort_order: Sequence[str] | None = None,
    case_sensitive: bool = False,
) -> Generator[
    tuple[tuple[Any, ...], fsspec.AbstractFileSystem, Sequence[str], dict], None, None
]:
    """Identify files based on `files_pattern` and return groups based on `group_by`.

    The function generates a tuple for each unique group containing the group names
    (specified by group_by), list of file paths, and group metadata.

    :param image_path: Directories to search for images or a list of image file paths
    :param files_pattern: File pattern for images if image_path is a directory.
    :param subset: Image keys to include if image_path is a directory. Use * for wildcard. For example A2-* will include
        all tiles in well A2.
    :param group_by: Groups (in `files_pattern`) to group by. Use `()` for no grouping and `(*)` to group all images
        together
    :param scenes: Whether to read all scenes in an image or a list of scene ids
    :param file_sort_order: Order of files within a group
    :param case_sensitive: Whether to use case-sensitive patterns
    :return Tuple of group names, file paths, and group metadata.
    """
    if file_sort_order is not None and len(file_sort_order) == 0:
        file_sort_order = None

    def _get_image_key_func(group_by):
        if len(group_by) == 0:  # no grouping, each image is a separate group
            return lambda x, m: (m.string,)
        elif len(group_by) == 1 and group_by[0] == "*":  # group all images together
            return lambda x, m: ("image",)
        else:
            return lambda x, m: tuple(x[g] for g in group_by)

    subset_ = subset  # for error message
    flags = re.NOFLAG if case_sensitive else re.IGNORECASE
    subset = _create_subset_function(subset, flags=flags)
    if group_by is None:
        group_by = ()
    image_paths = image_path
    if not isinstance(image_paths, (list, tuple)):
        image_paths = [image_paths]

    assert isinstance(group_by, (list, tuple)), "group_by must be a list or tuple"
    files_pattern_specified = files_pattern is not None and files_pattern != ""
    if files_pattern is None:
        files_pattern = "*"
    if isinstance(files_pattern, str):
        file_regex, extension, keys = _create_file_regex(files_pattern, flags)
        if files_pattern_specified:
            filtered_group_by = tuple([g for g in group_by if g in keys or g == "*"])

            if len(filtered_group_by) != len(group_by):
                raise ValueError(
                    f"Group by missing from pattern: {','.join(set(group_by) - set(filtered_group_by))}."
                )
    else:
        file_regex = files_pattern
        extension = ""
    _image_key_func = _get_image_key_func(group_by)
    group_to_matches = defaultdict(
        lambda: []
    )  # key is tuple -> value is tuple of group, dict
    maxdepth = None

    for image_path in image_paths:
        if isinstance(image_path, Path):
            # IF URI DO NOT PROVIDE AS PATH
            image_path = str(image_path.resolve())
        root = None
        if not isinstance(image_path, zarr.Group):
            try:
                root = zarr.open(image_path, mode="r")
            except:  # noqa: E722
                pass
        else:
            root = image_path

        if root is not None:
            if "0" not in root:  # format: "path.zarr/images/"
                if "images" in root:
                    images_group = root["images"]
                elif "labels" in root:
                    images_group = root["labels"]
                else:
                    images_group = root

                for name in images_group.group_keys():
                    m = file_regex.match(name)
                    if m:
                        d = m.groupdict()
                        group = _image_key_func(d, m)
                        image_key = "-".join(group)
                        if subset(image_key):
                            x = images_group[name]
                            group_to_matches[group].append((x, d))
            else:
                x = root
                name = Path(x.store.path).stem
                m = file_regex.match(name)
                if m:
                    d = m.groupdict()
                    group = _image_key_func(d, m)
                    image_key = "-".join(group)
                    if subset(image_key):
                        group_to_matches[group].append((x, d))
        elif image_path.lower().endswith(".csv") or image_path.lower().endswith(
            ".parquet"
        ):
            df = (
                pd.read_csv(image_path)
                if image_path.lower().endswith(".csv")
                else pd.read_parquet(image_path)
            )
            if len(group_by) == 0 or (len(group_by) == 1 and group_by[0] == "*"):
                raise ValueError("Not implemented. Please specify groupby.")
            assert "image" in df.columns, f"'image' column not found in {image_path}."
            for g in group_by:
                assert g in df.columns, f"'{g}' column not found in {image_path}."
            for d in df.to_dict(orient="records"):
                group = tuple([str(d[g]) for g in group_by])
                image_key = "-".join(group)
                if subset(image_key):
                    image = d["image"]
                    del d["image"]
                    group_to_matches[group].append((image, d))
        else:
            fs, _ = fsspec.core.url_to_fs(image_path)
            if image_path in [".", "./"] and _get_fs_protocol(fs) == "file":
                image_path = fs.info(image_path)["name"].rstrip(".")
            image_prefix = None

            if fs.isdir(image_path):
                image_path = image_path.rstrip(fs.sep)
                if maxdepth is None:
                    maxdepth = 0
                    for pattern_part in file_regex.pattern.split("/"):
                        if not pattern_part.endswith("\\"):
                            maxdepth += 1
                    maxdepth = max(1, maxdepth)
                image_path = fs.info(image_path)["name"]  # convert to absolute path
                all_paths = sorted(
                    fs.find(
                        f"{image_path}{fs.sep}",
                        maxdepth=maxdepth,
                        refresh=True,
                        withdirs=True,
                    )
                )

                paths = [p for p in all_paths if p.lower().endswith(extension)]
                if len(paths) == 0:
                    # try with no maxdepth
                    all_paths = sorted(
                        fs.find(
                            f"{image_path}{fs.sep}",
                            maxdepth=None,
                            refresh=True,
                            withdirs=True,
                        )
                    )
                    paths = [p for p in all_paths if p.lower().endswith(extension)]
                assert len(paths) > 0, f"No files found in {image_path}"
                image_prefix = f"{image_path}{fs.sep}"
            else:
                paths = [image_path]
            if _get_fs_protocol(fs) != "file":
                paths = [f"{_get_fs_protocol(fs)}://{x}" for x in paths]

            for x in paths:
                x_stripped = x
                if image_prefix is not None:
                    # strip prefix so that pattern matches from beginning of {image_path} only
                    index = x.find(image_prefix)
                    if index != -1:
                        x_stripped = x[index + len(image_prefix) :]
                m = file_regex.match(x_stripped)

                if m:
                    d = m.groupdict()
                    group = _image_key_func(d, m)
                    image_key = "-".join(group)

                    if subset(image_key):
                        group_to_matches[group].append((x, d))

    if len(group_to_matches) == 0:
        message = [f"No files found matching pattern: {files_pattern}"]
        if subset_ is not None:
            message.append(f", subset: {', '.join([str(s) for s in subset_])}")
        if len(group_by) > 0:
            message.append(f", group by: {', '.join(group_by)}")
        image_paths = [str(path) for path in image_paths]
        message.append(f" in {', '.join(image_paths)}.")
        raise ValueError("".join(message))

    scene_ids = [
        None
    ]  # get scene ids from 1st file in 1st group (assume they are all the same)

    if isinstance(scenes, list):
        scene_ids = scenes
        scenes = False

    def file_sort_key(x):
        x = x[0].name if isinstance(x[0], (zarr.Group, zarr.Array)) else x[0]
        if file_sort_order is not None:
            for i in range(len(file_sort_order)):
                x = x.replace(file_sort_order[i], str(i))
        return x

    for group in natsorted(group_to_matches):
        matches = natsorted(group_to_matches[group], key=file_sort_key)

        file_list = []
        file_metadata = []
        for m in matches:
            file_list.append(m[0])
            file_metadata.append(m[1])

        if scenes:
            scenes = False
            image0_path = file_list[0]
            image0_path_local = _localize_path(image0_path)
            if image0_path_local is not None:
                image0_path = image0_path_local
            image = _create_image(image0_path)
            try:
                with warnings.catch_warnings():
                    warnings.simplefilter("ignore")
                    scene_ids = image.scenes
                if scene_ids is None or len(scene_ids) <= 1:
                    scene_ids = [None]
            except:  # noqa: E722
                # some files with no scenes throw exception when accessing image.scenes
                scene_ids = [None]
            if image0_path_local is not None:
                os.remove(image0_path_local)

        for scene_id in scene_ids:
            image_key = group if scene_id is None else group + (scene_id,)
            image_key = "-".join(image_key)
            image_key = image_key.replace(
                "/", "-"
            )  # zarr does not support / in group names

            if not subset(image_key):  # need to filter again if filtering scene
                continue
            group_metadata = dict(
                group=dict(zip(group_by, group)),
                src=file_list,
                common_src=mlcs(
                    [
                        Path(x).stem
                        if not isinstance(x, zarr.Group)
                        else _get_store_path(x)
                        for x in file_list
                    ]
                ),
            )
            metadata = dict(
                file_metadata=file_metadata,
                scene_id=scene_id,
                id=image_key,
                group_metadata=group_metadata,
            )

            yield group, file_list, metadata


def _join(*paths: Sequence[str], sep: str):
    """Join paths using the specified separator.

    :param paths: List of paths
    :param sep: Path separator
    :return: Joined string
    """
    s = []
    npaths = len(paths)
    for i in range(npaths):
        v = paths[i]
        if len(v) > 0:
            if i != (npaths - 1) and v[-1] == sep:  # keep trailing separator only
                v = v[:-1]
            if len(v) > 0:
                s.append(v)
    return sep.join(s)


class _LazyLoadImage(_LazyLoadData):
    """A class for lazy loading of image data, supporting Dask and scene selection.

    :param file_list: list[str] | zarr.Group
        A list of file paths or a Zarr group containing the images.
    :param attrs: Mapping[Any, Any]
        Attributes containing metadata for the images.
    :param dask: bool
        Whether to use Dask for lazy loading of the images.
    :param scene_id: str
        The ID of the specific scene to read from a multi-scene file.
    :param kwargs: dict
        Additional arguments passed to the image processing functions.

    :example:
    .. code-block:: python

        # Example usage of _LazyLoadImage
        lazy_image = _LazyLoadImage(
            file_list=["image1.tiff", "image2.tiff"],
            attrs=metadata,
            dask=True,
            scene_id="Scene1",
        )
    """

    def __init__(
        self,
        file_list: list[str] | zarr.Group,
        attrs: Mapping[Any, Any],
        dask: bool,
        scene_id: str,
        **kwargs,
    ):
        super().__init__()
        self._file_list = file_list
        self._attrs = attrs
        self._dask = dask
        self._scene_id = scene_id
        self._kwargs = kwargs
        self._localized = False  # whether non-local nd2 files have been downloaded

    @property
    def data(self):
        """Load data from images."""
        if not self._localized:
            self._localized = True
            self._file_list = list(self._file_list)
            for i in range(len(self._file_list)):
                path = self._file_list[i]
                if isinstance(path, str):
                    local_path = _localize_path(path)
                    if local_path is not None:
                        path = local_path
                        # delete downloaded file when experiment is finalized
                        weakref.finalize(self, lambda: os.remove(local_path))

                        self._file_list[i] = path

        return _images2fov(
            self._file_list, self._attrs, self._dask, self._scene_id, **self._kwargs
        )


def _load_experiment(experiment: Experiment) -> None:
    """Loads all images from an experiment into memory in parallel.

    :param experiment: Experiment
        The experiment object containing the images to be loaded.
    :return: None

    :example:
    .. code-block:: python

        # Example usage of _load_experiment
        _load_experiment(my_experiment)
    """
    b = from_sequence(experiment.images.keys())

    def _load_image(key):
        experiment.images[key]

    bag = b.starmap(_load_image)
    with ProgressBar():
        bag.compute()
    return experiment


def _single_contrast(data: np.ndarray, display_ranges: Any) -> tuple[float, float]:
    """Calculates the contrast range (min and max) for a single image.

    :param data: np.ndarray
        The image data for which to calculate the contrast range.
    :param display_ranges: Any
        The display ranges to use for calculating the contrast. If not provided, the min and max of the data are used.
    :return: tuple[float, float]
        A tuple containing the minimum and maximum values for contrast adjustment.

    :example:
    .. code-block:: python

        # Example usage of _single_contrast
        min_val, max_val = _single_contrast(image_data, display_ranges)
    """
    try:
        min, max = np.array(display_ranges).flat[:2]
    except ValueError:
        min, max = data.min(), data.max()
    return min, max


ramp = list(range(256))
ZERO = [0] * 256
RED = ramp + ZERO + ZERO
GREEN = ZERO + ramp + ZERO
MAGENTA = ramp + ZERO + ramp
GRAY = ramp + ramp + ramp
CYAN = ZERO + ramp + ramp

DEFAULT_LUTS = GRAY, GREEN, RED, MAGENTA, CYAN, GRAY, GRAY


def _infer_luts_display_ranges(
    data: np.ndarray, luts: list | None, display_ranges: list | None
) -> tuple[list, list]:
    """Infers the lookup tables (LUTs) and display ranges for a given image data.

    :param data: np.ndarray
        The image data for which to infer LUTs and display ranges.
    :param luts: list | None
        The list of LUTs to use, or None to infer default LUTs.
    :param display_ranges: list | None
        The display ranges to use, or None to infer ranges from the data.
    :return: tuple[list, list]
        A tuple containing the inferred LUTs and display ranges.

    :example:
    .. code-block:: python

        # Example usage of _infer_luts_display_ranges
        luts, ranges = _infer_luts_display_ranges(
            image_data, luts=None, display_ranges=None
        )
    """
    nchannels = data.shape[-3]
    if luts is None:
        luts = DEFAULT_LUTS + (GRAY,) * (nchannels - len(DEFAULT_LUTS))

    if display_ranges is None:
        display_ranges = [None] * nchannels

    for i, dr in enumerate(display_ranges):
        if dr is None:
            x = data[..., i, :, :]
            display_ranges[i] = x.min(), x.max()
    if len(luts) < nchannels or len(display_ranges) < nchannels:
        error = "Must provide at least {} luts and display ranges"
        raise IndexError(error.format(nchannels))
    else:
        luts = luts[:nchannels]
        display_ranges = display_ranges[:nchannels]

    return luts, display_ranges


def _imagej_description(
    leading_shape: tuple[int, ...],
    leading_axes: str,
    contrast: list | None = None,
    display_mode: str = "composite",
) -> str:
    """Generates an ImageJ description string based on the provided image properties.

    :param leading_shape: tuple[int, ...]
        The shape of the leading dimensions of the image.
    :param leading_axes: str
        The labels of the leading axes (e.g., "XYZCT").
    :param contrast: list | None, optional
        The contrast settings for each channel (default is None).
    :param display_mode: str, optional
        The display mode for ImageJ (default is "composite").
    :return: str
        The generated ImageJ description string.

    :example:
    .. code-block:: python

        # Example usage of _imagej_description
        description = _imagej_description((512, 512, 3), "XYZ")
    """
    if len(leading_shape) != len(leading_axes):
        error = "mismatched axes, shape is {} but axis labels are {}"
        raise ValueError(error.format(leading_shape, leading_axes))

    description = [f"ImageJ=1.49v\n{np.prod(leading_shape)}"]
    sizes = {k: v for k, v in zip(leading_axes, leading_shape)}
    if "C" in sizes:
        description.append(f"channels={sizes['C']}\n")
    if "Z" in sizes:
        description.append(f"slices={sizes['Z']}\n")
    if "T" in sizes:
        description.append(f"frames={sizes['T']}\n")
    if contrast is not None:
        description.append("min={mini}\nmax={maxi}\n")
    description.append(f"hyperstack=true\nmode={display_mode}\n")

    return "".join(description)


def _ij_tag_50838(nchannels):
    """ImageJ uses tag 50838 to indicate size of metadata elements (e.g., 768 bytes per ROI)
    Parameter `nchannels` must accurately describe the length of the display ranges and LUTs, or the
    values imported into LUTs will be shifted in memory.

    :param nchannels:
    :return:
    """
    info_block = (20,)  # summary of metadata fields
    display_block = (16 * nchannels,)  # display range block
    luts_block = (256 * 3,) * nchannels  #
    return info_block + display_block + luts_block


def _ij_tag_50839(luts, display_ranges):
    """ImageJ uses tag 50839 to store metadata.

    Only range and luts are implemented here.
    :param tuple luts: tuple of 256*3=768 8-bit ints specifying RGB, e.g., constants io.RED etc.
    :param tuple display_ranges: tuple of (min, max) pairs for each channel
    :return:
    """
    d = struct.pack(
        "<" + "d" * len(display_ranges) * 2, *[y for x in display_ranges for y in x]
    )
    # insert display ranges
    tag = (
        "".join(
            [
                "JIJI",
                "gnar\x01\x00\x00\x00",
                "stul%s\x00\x00\x00" % chr(len(luts)),
            ]
        ).encode("ascii")
        + d
    )
    tag = struct.unpack("<" + "B" * len(tag), tag)
    return tag + tuple(sum([list(x) for x in luts], []))


def save_stack_imagej(
    uri: str,
    data: np.ndarray,
    luts: tuple[Sequence[int], ...] | None = None,
    display_ranges: tuple[tuple[int, int], ...] | None = None,
    resolution: float = 1.0,
    compress: Literal[0, 1] = 0,
    dimensions: str = None,
    display_mode: Literal["composite", "color", "grayscale"] = "composite",
):
    """
    Taken and modified from https://github.com/blaineylab/OpticalPooledScreens.

    Saves `data` as tiff file with imageJ compatibility.

    :param uri: Path or url to store the tiff file
    :param data: an array with 5, 4, 3, or 2 dimensions [TxZxCxYxX]
    :param luts:  ImageJ lookup table for each channel (e.g, scallops.io.GRAY, scallops.io.GREEN, etc)
    :param display_ranges: The display range can be set with a list of (min, max) pairs for each channel.
    :param resolution: Resolution of the image in microns per pixel
    :param compress: Compress the image. Setting to 1 saves a lot of space for integer masks
    :param dimensions: Dimensionality of the data. Leading dimenstions in order (i.e. TCZ, TC, CT)
    :param display_mode: Sets the display mode, where mode is "composite", "color" or "grayscale"

    >>> random_data = np.random.randint(0, 2**16, size=(3, 100, 100), dtype=np.uint16)
    >>> ramp = list(range(256))
    >>> ZERO = [0] * 256
    >>> RED = ramp + ZERO + ZERO
    >>> GREEN = ZERO + ramp + ZERO
    >>> BLUE = ZERO + ZERO + ramp
    >>> luts = GREEN, RED, BLUE
    >>> display_ranges = (0, 60000), (0, 40000), (0, 20000)
    >>> save_stack_imagej(
    ...     "random_image.tiff", random_data, luts=luts, display_ranges=display_ranges
    ... )

    Compatible array data types are:
        bool (converted to uint8 0, 255)
        uint8
        uint16
        float32
        float64 (converted to float32)
    """
    fs, _ = fsspec.core.url_to_fs(uri)
    name = uri

    if _get_fs_protocol(fs) != "file":
        # can not write non-local tiff files
        fd, name = tempfile.mkstemp(suffix=".tiff")
        os.close(fd)

    assert name.endswith((".tif", ".tiff")), (
        "Only tif formats (.tif, .tiff) are implemented"
    )

    if isinstance(data, list):
        data = np.array(data)

    assert 2 <= data.ndim <= 5, (
        "Input has shape {}, but number of dimensions must be in range [2, 5]"
    )

    if data.dtype in (np.int32, np.int64):
        if (data.min() >= 0) and (data.max() < 2**16):
            data = data.astype(np.uint16)
        else:
            data = data.astype(np.float32)
    elif data.dtype == np.float64:
        data = data.astype(np.float32)
    elif data.dtype == bool:
        data = 255 * data.astype(np.uint8)

    if data.dtype not in (np.uint8, np.uint16, np.float32):
        raise ValueError("Cannot save data of type %s" % data.dtype)

    resolution = (1.0 / resolution,) * 2

    if data.ndim == 2:
        # simple description
        mini, maxi = _single_contrast(data, display_ranges)
        description = f"ImageJ=1.49v\nimages=1\nmin={mini}\nmax={maxi}"
        imsave(
            name,
            data,
            photometric="minisblack",
            description=description,
            resolution=resolution,
            compress=compress,
        )
    else:
        # hyperstack description
        nchannels = data.shape[-3]
        luts, display_ranges = _infer_luts_display_ranges(data, luts, display_ranges)

        leading_shape = data.shape[:-2]
        if dimensions is None:
            dimensions = "TZC"[::-1][: len(leading_shape)][::-1]

        if "C" not in dimensions:
            contrast = _single_contrast(data, display_ranges)
            description = _imagej_description(
                leading_shape, dimensions, contrast=contrast
            )
            imsave(
                name,
                data,
                photometric="minisblack",
                description=description,
                resolution=resolution,
                compress=compress,
            )
        else:
            # the full monty
            description = _imagej_description(
                leading_shape, dimensions, display_mode=display_mode
            )
            # metadata encoding LUTs and display ranges
            # see http://rsb.info.nih.gov/ij/developer/source/ij/io/TiffEncoder.java.html
            tag_50838 = _ij_tag_50838(nchannels)
            tag_50839 = _ij_tag_50839(luts, display_ranges)

            imsave(
                name,
                data,
                photometric="minisblack",
                description=description,
                resolution=resolution,
                compress=compress,
                extratags=[
                    (50838, "I", len(tag_50838), tag_50838, True),
                    (50839, "B", len(tag_50839), tag_50839, True),
                ],
            )

        if _get_fs_protocol(fs) != "file":
            fs.put(name, uri)
            os.remove(name)


def pluralize(s: str, number: int):
    return s + "s" if number != 1 else s


def create_multiscene_hyperstack(
    uri: str, images: Dict[str, xr.DataArray], output_order: str = "ctzyx", **kwargs
):
    """Create a multi-scene hyperstack image from a dictionary of xarray DataArrays.

    This function creates a multi-scene hyperstack image from a dictionary of xarray DataArrays,
    where each DataArray represents an image scene. The images are arranged according to the specified
    output order.

    :param uri: URI to save the multi-scene hyperstack image.
    :param images: Dictionary containing image scenes, where keys are scene names and values are xarray DataArrays.
    :param output_order: Order of dimensions in the output hyperstack. Defaults to 'ctzyx'.
                         Supported dimensions are 's', 'c', 't', 'z', 'y', and 'x'.
    :param kwargs: Additional arguments to pass to OmeTiffWriter.save().

    Example:

    .. code-block:: python

        import scallops.io
        import xarray as xr
        import numpy as np

        # Create example image scenes
        scene1 = xr.DataArray(
            np.random.rand(1, 3, 10, 512, 512), dims=("c", "t", "z", "y", "x")
        )
        scene2 = xr.DataArray(
            np.random.rand(1, 3, 10, 512, 512), dims=("c", "t", "z", "y", "x")
        )

        # Create a dictionary of image scenes
        images = {"Scene1": scene1, "Scene2": scene2}

        # Define output URI
        output_uri = "path/to/output/multiscene_hyperstack.tiff"

        # Create the multi-scene hyperstack image
        scallops.io.create_multiscene_hyperstack(output_uri, images)
    """
    assert all([isinstance(x, xr.DataArray) for x in images.values]), (
        "All arrays must be xarrays"
    )
    assert set(output_order) <= set("sctzyx"), (
        "output_order can only contain s, c, tm z, y, and x"
    )

    names, data = zip(
        *[
            (k, forceTCZYX(arr).transpose(*list(output_order)))
            for k, arr in images.items()
        ]
    )
    channel_names = [[f"{y}" for y in x.c.values] for x in data]

    fs, _ = fsspec.core.url_to_fs(uri)
    local_path = uri
    if _get_fs_protocol(fs) != "file":
        # can not write non-local tiff files
        fd, local_path = tempfile.mkstemp(suffix=".tiff")
        os.close(fd)

    OmeTiffWriter.save(
        data=[x.values for x in data],
        dim_order=output_order.upper(),
        channel_names=channel_names,
        uri=local_path,
        metadata={"scenes": names},
        image_name=names,
        **kwargs,
    )
    if _get_fs_protocol(fs) != "file":
        fs.put(local_path, uri)
        os.remove(local_path)
